{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preparing the Wrold Cup Workload\n",
    "import sklearn as sl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "csv_file = 'https://raw.githubusercontent.com/nimamahmoudi/faas-keep-alive-modeling/master/datasets/wc98/invocation_count.csv'\n",
    "df = pd.read_csv(csv_file, index_col=0, parse_dates=True)\n",
    "f = plt.figure(figsize=(10,12))\n",
    "df['1998-06-30 08:00:01':'1998-07-01 08:00:00'].plot()\n",
    "users = df['1998-06-30 08:00:01':'1998-07-01 08:00:00'].values\n",
    "plt.subplot(211)\n",
    "plt.plot(users)\n",
    "scaling = sl.preprocessing.MinMaxScaler()\n",
    "scaled_users = np.ceil(120*scaling.fit_transform(users)).astype(int)\n",
    "plt.subplot(212)\n",
    "plt.plot(scaled_users)\n",
    "plt.show(block = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Importing Necessary Libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from kubernetes import client, config\n",
    "tf.reset_default_graph()  # This is to reset the graph\n",
    "output = subprocess.check_output('kubectl get pods', shell=True)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/jupyter/google.json\"\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "\n",
    "##############\n",
    "## PID Parameters\n",
    "KP = 0.0004\n",
    "KI = 0.0004\n",
    "KD = 0.00005\n",
    "r = 800\n",
    "e = np.zeros([3,1])\n",
    "resp=np.zeros([5,1])\n",
    "rps=np.zeros([5,1])\n",
    "cont_rq=np.zeros([5,1])\n",
    "cont_rd=np.zeros([5,1])\n",
    "users=np.zeros([5,1])\n",
    "e_pre = np.zeros([3,1])\n",
    "x_PID_old = np.zeros([3,1])\n",
    "x_PID_new = np.zeros([3,1])\n",
    "eta_controller = 2e-12\n",
    "eta_prev = eta_controller\n",
    "max_input_user = 1\n",
    "min_input_user = 0\n",
    "max_input_cont = 1\n",
    "min_input_cont = 0\n",
    "max_output_resp = 1\n",
    "min_output_resp = 0\n",
    "max_rps = 1\n",
    "min_rps = 0\n",
    "min_users = 0\n",
    "max_users = 1\n",
    "resp[0] = 0\n",
    "resp[1] = 0\n",
    "resp[2] = 0\n",
    "resp[3] = 0\n",
    "resp[4] = 0\n",
    "cont_rq[0]=1\n",
    "cont_rq[1]=1\n",
    "cont_rq[2]=1\n",
    "cont_rq[3]=1\n",
    "cont_rq[4]=1\n",
    "cont_rd[0]=1\n",
    "cont_rd[1]=1\n",
    "cont_rd[2]=1\n",
    "cont_rd[3]=1\n",
    "rps[0] = 0\n",
    "rps[1] = 0\n",
    "rps[2] = 0\n",
    "rps[3] = 0\n",
    "rps[4] = 0\n",
    "fil_resp = np.zeros([5,1]) \n",
    "############## \n",
    "# Neural Network Parameters\n",
    "n_hidden = 40\n",
    "n_classes = 1\n",
    "n_input = 9\n",
    "eta = 1e-4\n",
    "y_train=np.zeros([1,1])\n",
    "x_train=np.zeros([1,1])\n",
    "\n",
    "############## \n",
    "#### Defining the Neural Network Model Identifier, one can add more layers to make it deeper \n",
    "\n",
    "def multilayer_perceptron(x):\n",
    "    fc1=tf.layers.dense(x, n_hidden,activation=tf.nn.tanh,name=\"FL\")\n",
    "    #fcd=tf.layers.dropout(inputs=fc1,rate=0.5,training=True)\n",
    "    #fc2=tf.layers.dense(fc1, 10,activation=tf.nn.elu,name=\"FL2\")\n",
    "    #fcd2=tf.layers.dropout(inputs=fc2,rate=0.1,training=True)\n",
    "    #fcd2=tf.layers.dropout(inputs=fc2,rate=0.5)\n",
    "    #fc3=tf.layers.dense(fc2, 10,activation=tf.nn.elu,name=\"FL3\")\n",
    "    #fcd3=tf.layers.dropout(inputs=fc3,rate=0.1,training=True)\n",
    "    #fc3=layers.fully_connected(fc2, 20,activation_fn=tf.nn.elu,scope='FC3')\n",
    "    out=tf.layers.dense(fc1,n_classes,activation=None,name=\"OL\") \n",
    "    return out\n",
    "\n",
    "# build model, loss, and train op\n",
    "x = tf.placeholder(tf.float32, [None, n_input], name='placeholder_x')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name='placeholder_y')\n",
    "y_hat = multilayer_perceptron(x)\n",
    "loss = tf.reduce_mean(tf.square(y-y_hat))\n",
    "train = tf.train.AdamOptimizer(learning_rate= eta).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "#sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, dir_path + \"/Model-small-new.ckpt\")\n",
    "config.load_kube_config()\n",
    "#%%\n",
    "DEPLOYMENT_NAME = 'wordpress'\n",
    "DEPLOYMENT_NS = 'default'\n",
    "\n",
    "\n",
    "api_instance = client.ExtensionsV1beta1Api()\n",
    "\n",
    "def get_replica_and_ready():\n",
    "    api_response = api_instance.read_namespaced_deployment(DEPLOYMENT_NAME, DEPLOYMENT_NS)\n",
    "    return api_response.status.replicas, api_response.status.ready_replicas\n",
    "\n",
    "def set_replica_num(rnum):\n",
    "    rnum = int(rnum)\n",
    "    if rnum < 1:\n",
    "        rnum = 1\n",
    "    api_response = api_instance.read_namespaced_deployment(DEPLOYMENT_NAME, DEPLOYMENT_NS)\n",
    "    api_response.spec.replicas = rnum\n",
    "    api_instance.patch_namespaced_deployment_scale(DEPLOYMENT_NAME, DEPLOYMENT_NS, api_response)\n",
    "u_pre = 6\n",
    "set_replica_num(u_pre)\n",
    "print(get_replica_and_ready())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Change working directory from the workspace root to the ipynb file location. Turn this addition off with the DataScience.changeDirOnImportExport setting\n",
    "import os\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), 'examples'))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    pass\n",
    "import pacs_load_tester as load_tester\n",
    "moshtagh = np.zeros((1,13))\n",
    "\n",
    "#%%\n",
    "def custom_sensing():\n",
    "    r1,r2 = get_replica_and_ready()\n",
    "    return {'r1':r1 , 'r2':r2 , 'KP':KP, 'KI':KI , 'KD':KD}\n",
    "lt = load_tester.pacsLoadTester(hatch_rate=1, temp_stat_max_len=5, base='http://35.232.158.172:8089/')\n",
    "\n",
    "lt.custom_sensing = custom_sensing\n",
    "lt.custom_sensing()\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "loop_timer = load_tester.TimerClass()\n",
    "total_timer = load_tester.TimerClass()\n",
    "user_sequence = [30,60,30,60,30]\n",
    "\n",
    "lt.custom_sensing = custom_sensing\n",
    "lt.change_count(user_sequence[0])\n",
    "lt.start_capturing()\n",
    "\n",
    "loop_time_in_secs = load_tester.get_loop_time_in_secs('20s')\n",
    "\n",
    "loop_timer.tic()\n",
    "total_timer.tic()\n",
    "results = None\n",
    "#old_response = 300\n",
    "for i in tqdm(range(len(user_sequence)*36)):\n",
    "    print(\"U(t)  : \", u_pre)\n",
    "    user_count = user_sequence[math.floor(i/36)]\n",
    "    lt.change_count(user_count)\n",
    "    sleep_time = loop_time_in_secs - loop_timer.toc()\n",
    "    if sleep_time > 0:\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    loop_timer.tic()\n",
    "\n",
    "    result = lt.get_all_stats()\n",
    "    df_result = pd.DataFrame(data=result)\n",
    "\n",
    "    if results is None:\n",
    "        results = df_result\n",
    "    else:\n",
    "        results = results.append(df_result)\n",
    "\n",
    "\n",
    "    #####Identification\n",
    "    if (result['current_response_time_average'])!=[]:\n",
    "        if result['current_response_time_average'][-1]!=None :\n",
    "            cont_rq[0] =  np.nanmean(np.array(np.ceil(u_pre)))\n",
    "            \n",
    "            #cont_rq[0] = u_pre\n",
    "            cont_rq[1] = (cont_rq[1]-min_input_cont)/(max_input_cont-min_input_cont)\n",
    "            cont_rq[2] = (cont_rq[2]-min_input_cont)/(max_input_cont-min_input_cont)\n",
    "            cont_rq[3] = (cont_rq[3]-min_input_cont)/(max_input_cont-min_input_cont)\n",
    "            cont_rq[4] = (cont_rq[4]-min_input_cont)/(max_input_cont-min_input_cont)\n",
    "            cont_rd[0]= np.nanmean(np.array(result['custom_r2'][-1]))\n",
    "            resp[0] = (np.nanmean(np.array(result['current_response_time_average'],dtype=float))-min_output_resp)/(max_output_resp-min_output_resp) \n",
    "            resp[1] =(resp[1]-min_output_resp)/(max_output_resp-min_output_resp)\n",
    "            resp[2] =(resp[2]-min_output_resp)/(max_output_resp-min_output_resp)\n",
    "            resp[3] =(resp[3]-min_output_resp)/(max_output_resp-min_output_resp)\n",
    "            resp[4] =(resp[4]-min_output_resp)/(max_output_resp-min_output_resp)\n",
    "            fil_resp[0:4] = resp[0:4]\n",
    "            rps[0] = (np.nanmean(np.array(result['current_rps'][-1],dtype=float))-min_rps)/(max_rps-min_rps)\n",
    "            rps[1] = (rps[1]-min_rps)/(max_rps-min_rps)\n",
    "            rps[2] = (rps[2]-min_rps)/(max_rps-min_rps)\n",
    "            rps[3] = (rps[3]-min_rps)/(max_rps-min_rps)\n",
    "            rps[4] = (rps[4]-min_rps)/(max_rps-min_rps)\n",
    "\n",
    "            users[0] = (np.nanmean(np.array(result['user_count'],dtype=float))-min_users)/(max_users-min_users)\n",
    "            users[1] = (users[1]-min_users)/(max_users-min_users)\n",
    "            users[2] = (users[2]-min_users)/(max_users-min_users)\n",
    "            users[3] = (users[3]-min_users)/(max_users-min_users)\n",
    "            users[4] = (users[4]-min_users)/(max_users-min_users)\n",
    "            r_normalized = (r-min_output_resp)/(max_output_resp-min_output_resp)\n",
    "            batch_x = np.reshape([cont_rq[0]/40,cont_rq[1]/40,cont_rq[2]/40,cont_rd[1]/40,cont_rd[2]/40,cont_rd[3]/40,users[0]/150,users[1]/150,users[2]/150],(1,9))\n",
    "            batch_y = np.reshape(resp[0],(1,1))\n",
    "            print(\"batch_x : \",batch_x)\n",
    "            for epoch in range(1):\n",
    "                epoch_loss = 0.0\n",
    "                batch_steps =1\n",
    "                for i in range(batch_steps):\n",
    "                    _, c = sess.run([train, loss],\n",
    "                                       feed_dict={x: batch_x, y: batch_y})\n",
    "                    epoch_loss += c / batch_steps\n",
    "                    print ('Epoch %02d, Loss = %.12f , ' % (i, epoch_loss))\n",
    "                    y_now = sess.run(y_hat, feed_dict={x: batch_x})\n",
    "                    print(\"PREDICTION : \", y_now)\n",
    "\n",
    "            e_pre[0] = e[0]\n",
    "            e_pre[1] = e[1]\n",
    "            e_pre[2] = e[2]\n",
    "            e[0]= -(r_normalized - resp[0])\n",
    "            if e[0]>=-300 and e[0]<=0:\n",
    "                e[0] = 0\n",
    "            e[1]= e_pre[0]\n",
    "            e[2]= e_pre[1]\n",
    "            x_PID_old[0] = e_pre[0] - e_pre[1]\n",
    "            x_PID_old[1] = e_pre[0]  \n",
    "            x_PID_old[2] = e_pre[0] - 2*e_pre[1] + e_pre[2]\n",
    "            x_PID_new[0] = e[0] - e[1]\n",
    "            x_PID_new[1] = e[0]  \n",
    "            x_PID_new[2] = e[0] - 2*e[1] + e[2]            \n",
    "            print(\"Error (t+1) : \",e[0], \"Error (t) : \", e[1],\"Error (t-1) : \", e[2])\n",
    "\n",
    "            dy_du = tf.gradients(y_hat,x)\n",
    "            sensitivity= sess.run(dy_du,feed_dict={x:batch_x})\n",
    "            if np.abs(resp[0]-y_now)>=300 :\n",
    "                eta_controller = 0 \n",
    "            else :\n",
    "                eta_controller = eta_prev\n",
    "            delta_KP = 0.1*eta_controller*e[0]*sensitivity[0][0][0]*x_PID_old[0] \n",
    "            delta_KI = 0.1*eta_controller*e[0]*sensitivity[0][0][0]*x_PID_old[1] \n",
    "            delta_KD = 0.01*eta_controller*e[0]*sensitivity[0][0][0]*x_PID_old[2] \n",
    "            KP = KP - delta_KP\n",
    "            KI = KI - delta_KI\n",
    "            KD = KD - delta_KD\n",
    "            cont_rd[3]=cont_rd[2]\n",
    "            cont_rd[2]=cont_rd[1]\n",
    "            cont_rd[1]=cont_rd[0]\n",
    "            cont_rq[4]= cont_rq[3]\n",
    "            cont_rq[3]= cont_rq[2]\n",
    "            cont_rq[2]= cont_rq[1]\n",
    "            cont_rq[1]= cont_rq[0]\n",
    "            resp[4]=resp[3]\n",
    "            resp[3]=resp[2]\n",
    "            resp[2]=resp[1]\n",
    "            resp[1]=resp[0]\n",
    "            rps[4] = rps[3]\n",
    "            rps[3] = rps[2]\n",
    "            rps[2] = rps[1]\n",
    "            rps[1] = rps[0]\n",
    "            users[4] = users[3]\n",
    "            users[3] = users[2]\n",
    "            users[2] = users[1]\n",
    "            users[1] = users[0]\n",
    "            if u_pre ==40 or u_pre < 1:\n",
    "                x_PID_new[1] = 0  \n",
    "            u_pre = u_pre + KP*x_PID_new[0] + KI*x_PID_new[1] + KD*x_PID_new[2]\n",
    "            print(\"u(t+1) : \", u_pre)\n",
    "            default = u_pre\n",
    "            \n",
    "            if np.isnan(u_pre):\n",
    "                set_replica_num(np.floor(default))\n",
    "            if u_pre >= 40 :\n",
    "                u_pre = 40\n",
    "                try:\n",
    "                    set_replica_num(40)\n",
    "                except:\n",
    "                    print(\"Error occured !!!!!\")\n",
    "            elif u_pre <= 1 :\n",
    "                set_replica_num(1)\n",
    "                u_pre = 1\n",
    "            else :\n",
    "                try : \n",
    "                    set_replica_num(np.ceil(u_pre))\n",
    "                except : \n",
    "                    print(\"Exception !!!\")\n",
    "            print(\"KP : \",KP,\" KI : \",KI, \"KD : \",KD, \"Control Input : \",u_pre, \"Modeling Error : \",(resp[0]-y_now),\" Gradient : \",sensitivity[0][0][0])\n",
    "            print(\"X1 old: \",x_PID_old[0], \"X2 old: \",x_PID_old[1], \"X3 old: \",x_PID_old[2])\n",
    "            print(\"X1 new: \",x_PID_new[0], \"X2 new: \",x_PID_new[1], \"X3 new: \",x_PID_new[2])\n",
    "            print(\"delta_KP :\",delta_KP,\"delta_KI :\",delta_KI,\"delta_KD :\",delta_KD)\n",
    "        print(\"iteration : \",i ,\"average RSPT is: \",np.nanmean(np.array(result['current_response_time_average'],dtype=float)),\"Number of Replica Ready: \",result['custom_r2'][-1], \"Number of Users: \",user_count)\n",
    "        print(\" ERROR : \",e[0])\n",
    "        print(\"----------------------------------------------\")\n",
    "        \n",
    "lt.stop_test()\n",
    "\n",
    "results, filename = lt.prepare_results_from_df(results)\n",
    "\n",
    "results.head()\n",
    "\n",
    "res = results\n",
    "res = res[res['total_rps'] > 0]\n",
    "responsetime_avg = np.nanmean(np.array(res['current_response_time_average'],dtype=float))\n",
    "responsetime_var = np.sqrt(np.var(res['current_response_time_average']))\n",
    "container_avg = np.average(res['custom_r2'])\n",
    "container_var = np.sqrt(np.var(res['custom_r2']))\n",
    "print(\"average res : \", responsetime_avg , \"Var Res : \",responsetime_var, \"average Container : \",container_avg, \"Var Container : \", container_var )\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "plt.figure(figsize=(60,30),dpi=200)\n",
    "plt.subplot(511)\n",
    "#plt.plot(res['elapsed_min'], res['min_response_time'], label='min_response_time')\n",
    "#plt.plot(res['elapsed_min'], res['current_response_time_percentile_50'], label='median_response_time')\n",
    "plt.plot(res['elapsed_min'], res['current_response_time_average'], label='avg_response_time')\n",
    "plt.plot(res['elapsed_min'],r*np.ones(len(res['current_response_time_average'])), label='setpoint')\n",
    "#plt.plot(res['elapsed_min'], res['current_response_time_percentile_95'], label='95th percentile')\n",
    "#plt.plot(res['elapsed_min'], res['max_response_time'], label='max_response_time')\n",
    "plt.ylim((0,6000))\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Average Response Time (ms)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(512)\n",
    "plt.plot(res['elapsed_min'], res['user_count'])\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Num of Users')\n",
    "\n",
    "plt.subplot(513)\n",
    "plt.plot(res['elapsed_min'], res['total_rps'])\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Throughput (req/s)')\n",
    "\n",
    "plt.subplot(514)\n",
    "plt.plot(res['elapsed_min'], res['fail_ratio'])\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Fail Ratio')\n",
    "\n",
    "plt.subplot(515)\n",
    "plt.plot(res['elapsed_min'], res['custom_r1'])\n",
    "plt.plot(res['elapsed_min'], res['custom_r2'])\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Custom Value')\n",
    "\n",
    "\n",
    "\n",
    "filename = filename.replace('aa.csv', '')\n",
    "plt.savefig(filename + '.png', dpi=300)\n",
    "plt.savefig(filename + '.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
